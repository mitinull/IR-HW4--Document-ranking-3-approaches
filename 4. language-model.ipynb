{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing an Information Retrieval System with Document Ranking\n",
    "\n",
    "This project aims to augment the Information Retrieval (IR) system developed in the previous assignments by incorporating different Document Ranking strategies. You should use the Cranfield collection as the dataset. You can find\n",
    "that in the original format here or in the TREC XML format with binary tagging here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "In this project, you will implement three different approaches for document ranking, including the vector space model,\n",
    "the binary independence model, and the language model. Then, you need to compare these ranking models resorting\n",
    "to the evaluation criteria in Lecture 7. Key components and functionalities are as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⬜ Document Ranking – Language Model\n",
    "\n",
    "You will implement a function for document ranking utilizing\n",
    "the language model. The function will take as input a query text and an integer indicating the number of top\n",
    "documents to be retrieved. You can choose between Dirichlet smoothing or Jelinek-Mercer smoothing to avoid\n",
    "zeroes. You do not need to fine-tune parameters λ or α. Albeit, you need to discuss why your chosen methods\n",
    "and parameters are preferred.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  # For standard paths that work on both windows and linux\n",
    "import pickle  # For write/read dicts to/from files\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer  # For query tokenization\n",
    "from nltk.stem import PorterStemmer  # For query stemming\n",
    "import math # For calculating idf (log(N/df))\n",
    "from collections import Counter # For calculating query's terms frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading posting list from file\n",
    "# posting list has been created in the last step (preprocessing)\n",
    "posting_list = None\n",
    "docs = None\n",
    "tokenized_docs = None\n",
    "\n",
    "with open(Path(\"files\") / \"posting_list.pkl\", \"rb\") as f:\n",
    "        posting_list = pickle.load(f)\n",
    "\n",
    "with open(Path(\"files\") / \"docs.pkl\", \"rb\") as f:\n",
    "        docs = pickle.load(f)\n",
    "\n",
    "with open(Path(\"files\") / \"tokenized_docs.pkl\", \"rb\") as f:\n",
    "        tokenized_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but(219 docs): [doc_id: frequency] {13: 2, 24: 1, 27: 1, 43: 1, 48: 2, 61: 1, 65: 1, 71: 2, 93: 1, 109: 2, 113: 1, 115: 1, 124: 1, 125: 1, 131: 1, 137: 1, 139: 1, 148: 1, 151: 1, 152: 1, 155: 2, 159: 1, 167: 1, 172: 1, 175: 1, 178: 1, 184: 1, 187: 1, 188: 1, 190: 1, 192: 1, 198: 2, 200: 1, 201: 4, 203: 1, 205: 1, 208: 1, 209: 1, 211: 2, 213: 1, 220: 1, 226: 1, 228: 1, 240: 1, 243: 1, 246: 1, 251: 2, 254: 2, 260: 1, 265: 1, 271: 1, 282: 1, 283: 1, 291: 1, 295: 1, 328: 4, 337: 2, 346: 1, 347: 1, 351: 1, 369: 1, 374: 1, 389: 1, 403: 2, 416: 1, 430: 1, 440: 1, 451: 1, 458: 2, 476: 2, 483: 1, 489: 1, 498: 2, 510: 1, 514: 1, 518: 1, 519: 1, 520: 1, 521: 1, 526: 1, 535: 1, 544: 1, 546: 1, 555: 1, 561: 1, 563: 1, 565: 1, 566: 1, 568: 1, 569: 1, 571: 1, 588: 1, 594: 1, 599: 1, 603: 1, 635: 1, 639: 1, 642: 1, 651: 1, 659: 1, 660: 1, 662: 1, 666: 1, 670: 1, 672: 1, 678: 1, 684: 2, 685: 1, 691: 1, 703: 2, 717: 1, 720: 1, 726: 1, 730: 1, 738: 1, 747: 1, 751: 1, 752: 2, 755: 1, 756: 2, 759: 1, 762: 1, 785: 1, 795: 1, 796: 3, 797: 2, 798: 1, 808: 1, 809: 1, 810: 1, 813: 1, 817: 1, 819: 1, 823: 1, 841: 1, 867: 1, 868: 1, 872: 1, 873: 1, 876: 1, 882: 1, 888: 1, 891: 1, 901: 1, 902: 1, 907: 1, 908: 1, 910: 1, 912: 1, 922: 1, 927: 1, 929: 1, 932: 1, 961: 3, 965: 2, 976: 1, 983: 1, 984: 1, 989: 1, 993: 1, 999: 2, 1000: 1, 1006: 1, 1011: 1, 1034: 1, 1039: 1, 1041: 1, 1046: 2, 1050: 1, 1053: 1, 1065: 1, 1067: 1, 1074: 1, 1077: 1, 1081: 2, 1083: 1, 1109: 1, 1130: 1, 1135: 1, 1164: 1, 1174: 1, 1177: 1, 1181: 1, 1184: 1, 1187: 2, 1188: 1, 1205: 1, 1206: 1, 1209: 1, 1217: 1, 1219: 1, 1224: 1, 1234: 1, 1237: 1, 1238: 2, 1241: 2, 1243: 2, 1244: 1, 1259: 1, 1264: 1, 1270: 1, 1276: 1, 1302: 1, 1308: 1, 1315: 1, 1319: 1, 1320: 1, 1321: 1, 1324: 1, 1336: 1, 1342: 1, 1369: 1, 1371: 1, 1372: 1, 1374: 2, 1379: 1, 1383: 1, 1384: 1, 1391: 1}\n"
     ]
    }
   ],
   "source": [
    "print(f\"but({len(posting_list['but'])} docs): [doc_id: frequency]\",posting_list[\"but\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['experiment', 'investig', 'of', 'the', 'aerodynam'] + ...\n"
     ]
    }
   ],
   "source": [
    "# List of all tokens in the collection. (Make it by combining document tokens)\n",
    "collection_tokens = [j for sub in tokenized_docs for j in sub]\n",
    "print(collection_tokens[:5], \"+ ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiment': 470, 'investig': 524, 'of': 12671, 'the': 19444, 'aerodynam': 309}\n"
     ]
    }
   ],
   "source": [
    "# Number of occurrences in the collection for each term.\n",
    "collection_frequency = Counter(collection_tokens)\n",
    "print({term: collection_frequency[term] for term in collection_tokens[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiment': 0.0020734531818683137, 'investig': 0.002311679717657439, 'of': 0.055899415462666815, 'the': 0.0857791992941436, 'aerodynam': 0.001363185177015551}\n"
     ]
    }
   ],
   "source": [
    "# Probability of occurrence in the collection for each term.\n",
    "p_term_collection = {\n",
    "    key: collection_frequency[key] / len(collection_tokens)\n",
    "    for key in collection_frequency\n",
    "}\n",
    "print({term:p_term_collection[term] for term in collection_tokens[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000562"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of all probabilities must be one. (Just for testing)\n",
    "sum([p_term_collection[term] for term in p_term_collection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_0: {'experiment': 0.014388489208633094, 'investig': 0.007194244604316547, 'of': 0.07194244604316546, 'the': 0.08633093525179857, 'aerodynam': 0.007194244604316547, 'a': 0.050359712230215826, 'wing': 0.02158273381294964, 'in': 0.02877697841726619, 'slipstream': 0.03597122302158273, 'an': 0.02158273381294964, 'studi': 0.007194244604316547, 'propel': 0.007194244604316547, 'wa': 0.02877697841726619, 'made': 0.014388489208633094, 'order': 0.007194244604316547, 'to': 0.03597122302158273, 'determin': 0.007194244604316547, 'spanwis': 0.007194244604316547, 'distribut': 0.007194244604316547, 'lift': 0.02877697841726619, 'increas': 0.007194244604316547, 'due': 0.014388489208633094, 'at': 0.014388489208633094, 'differ': 0.02158273381294964, 'angl': 0.007194244604316547, 'attack': 0.007194244604316547, 'and': 0.007194244604316547, 'free': 0.007194244604316547, 'stream': 0.007194244604316547, 'veloc': 0.007194244604316547, 'ratio': 0.007194244604316547, 'result': 0.007194244604316547, 'were': 0.007194244604316547, 'intend': 0.007194244604316547, 'part': 0.014388489208633094, 'as': 0.007194244604316547, 'evalu': 0.014388489208633094, 'basi': 0.007194244604316547, 'for': 0.014388489208633094, 'theoret': 0.007194244604316547, 'treatment': 0.007194244604316547, 'thi': 0.014388489208633094, 'problem': 0.007194244604316547, 'compar': 0.007194244604316547, 'span': 0.007194244604316547, 'load': 0.007194244604316547, 'curv': 0.007194244604316547, 'togeth': 0.007194244604316547, 'with': 0.014388489208633094, 'support': 0.007194244604316547, 'evid': 0.007194244604316547, 'show': 0.007194244604316547, 'that': 0.007194244604316547, 'substanti': 0.007194244604316547, 'increment': 0.014388489208633094, 'produc': 0.007194244604316547, 'by': 0.007194244604316547, 'destal': 0.02158273381294964, 'or': 0.007194244604316547, 'boundari': 0.007194244604316547, 'layer': 0.007194244604316547, 'control': 0.007194244604316547, 'effect': 0.014388489208633094, 'integr': 0.007194244604316547, 'remain': 0.007194244604316547, 'after': 0.007194244604316547, 'subtract': 0.007194244604316547, 'found': 0.007194244604316547, 'agre': 0.007194244604316547, 'well': 0.007194244604316547, 'potenti': 0.007194244604316547, 'flow': 0.007194244604316547, 'theori': 0.007194244604316547, 'empir': 0.007194244604316547, 'specif': 0.007194244604316547, 'configur': 0.007194244604316547, 'experi': 0.007194244604316547}\n",
      "doc_1: {'simpl': 0.01015228426395939, 'shear': 0.01015228426395939, 'flow': 0.030456852791878174, 'past': 0.02030456852791878, 'a': 0.04568527918781726, 'flat': 0.015228426395939087, 'plate': 0.015228426395939087, 'in': 0.03553299492385787, 'an': 0.01015228426395939, 'incompress': 0.01015228426395939, 'fluid': 0.01015228426395939, 'of': 0.030456852791878174, 'small': 0.01015228426395939, 'viscos': 0.01015228426395939, 'the': 0.09137055837563451, 'studi': 0.01015228426395939, 'high': 0.005076142131979695, 'speed': 0.005076142131979695, 'viscou': 0.01015228426395939, 'two': 0.01015228426395939, 'dimension': 0.01015228426395939, 'bodi': 0.01015228426395939, 'it': 0.01015228426395939, 'is': 0.025380710659898477, 'usual': 0.005076142131979695, 'necessari': 0.005076142131979695, 'to': 0.01015228426395939, 'consid': 0.01015228426395939, 'curv': 0.005076142131979695, 'shock': 0.01015228426395939, 'wave': 0.01015228426395939, 'emit': 0.005076142131979695, 'from': 0.01015228426395939, 'nose': 0.005076142131979695, 'or': 0.005076142131979695, 'lead': 0.005076142131979695, 'edg': 0.005076142131979695, 'consequ': 0.005076142131979695, 'there': 0.005076142131979695, 'exist': 0.005076142131979695, 'inviscid': 0.015228426395939087, 'rotat': 0.01015228426395939, 'region': 0.005076142131979695, 'between': 0.005076142131979695, 'and': 0.01015228426395939, 'boundari': 0.025380710659898477, 'layer': 0.025380710659898477, 'such': 0.005076142131979695, 'situat': 0.01015228426395939, 'aris': 0.005076142131979695, 'for': 0.005076142131979695, 'instanc': 0.005076142131979695, 'hyperson': 0.01015228426395939, 'somewhat': 0.005076142131979695, 'differ': 0.005076142131979695, 'prandtl': 0.01015228426395939, 's': 0.01015228426395939, 'classic': 0.005076142131979695, 'problem': 0.02030456852791878, 'origin': 0.005076142131979695, 'free': 0.015228426395939087, 'stream': 0.015228426395939087, 'outsid': 0.005076142131979695, 'irrot': 0.005076142131979695, 'while': 0.005076142131979695, 'must': 0.005076142131979695, 'be': 0.02030456852791878, 'as': 0.005076142131979695, 'possibl': 0.005076142131979695, 'effect': 0.005076142131979695, 'vortic': 0.01015228426395939, 'have': 0.005076142131979695, 'been': 0.005076142131979695, 'recent': 0.005076142131979695, 'discuss': 0.01015228426395939, 'by': 0.01015228426395939, 'ferri': 0.005076142131979695, 'libbi': 0.005076142131979695, 'present': 0.005076142131979695, 'paper': 0.005076142131979695, 'investig': 0.005076142131979695, 'can': 0.01015228426395939, 'shown': 0.005076142131979695, 'that': 0.01015228426395939, 'thi': 0.005076142131979695, 'again': 0.005076142131979695, 'treat': 0.005076142131979695, 'approxim': 0.005076142131979695, 'onli': 0.005076142131979695, 'novel': 0.005076142131979695, 'featur': 0.005076142131979695, 'ha': 0.005076142131979695, 'constant': 0.005076142131979695, 'here': 0.005076142131979695, 'restrict': 0.005076142131979695, 'steadi': 0.005076142131979695}\n",
      "doc_2: {'the': 0.08, 'boundari': 0.08, 'layer': 0.08, 'in': 0.04, 'simpl': 0.04, 'shear': 0.04, 'flow': 0.08, 'past': 0.04, 'a': 0.04, 'flat': 0.04, 'plate': 0.04, 'equat': 0.04, 'are': 0.04, 'present': 0.04, 'for': 0.04, 'steadi': 0.04, 'incompress': 0.04, 'with': 0.04, 'no': 0.04, 'pressur': 0.04, 'gradient': 0.04}\n"
     ]
    }
   ],
   "source": [
    "# Probability of occurrence in the documents.\n",
    "p_term_document = [\n",
    "    {term: tf / len(doc_tokens) for term, tf in Counter(doc_tokens).items()}\n",
    "    for doc_tokens in tokenized_docs\n",
    "]\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"doc_{i}:\", p_term_document[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_0: 0.9999999999999981\n",
      "doc_1: 1.0000000000000009\n",
      "doc_2: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# Sum of all probabilities must be one. (Just for testing)\n",
    "for i in range(3):\n",
    "    print(f\"doc_{i}:\", sum([p_term_document[i][term] for term in p_term_document[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_score(query, k, l):\n",
    "    query = [ps.stem(token) for token in tokenizer.tokenize(query)]\n",
    "\n",
    "    docs_scores = np.ones(len(docs))\n",
    "\n",
    "    for doc_id in range(len(docs)):\n",
    "        for term in query:\n",
    "            docs_scores[doc_id] *= (\n",
    "                l * (p_term_document[doc_id].get(term) or 0) + (1 - l) * p_term_collection[term]\n",
    "            )\n",
    "\n",
    "    result_doc_ids = docs_scores.argsort()[-k:][::-1]\n",
    "\n",
    "    return [{\"id\": result_doc_ids[i], \"score\": docs_scores[result_doc_ids[i]]} for i in range(len(result_doc_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 495, 'score': 1.0944810384386183e-23},\n",
       " {'id': 902, 'score': 3.464452734490881e-26},\n",
       " {'id': 519, 'score': 9.723387370623949e-27},\n",
       " {'id': 312, 'score': 1.168978562256519e-27},\n",
       " {'id': 37, 'score': 9.542067045390059e-28}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = lm_score(\n",
    "    \"what is the basic mechanism of the transonic aileron buzz .\",\n",
    "    5,\n",
    "    l = .5\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Result 1 ==================\n",
      "a theory of transonic aileron buzz, neglecting viscous\n",
      "effects .\n",
      "  usaf-sponsored analysis of the unsteady perturbations of\n",
      "two-dimensional transonic flow around an airfoil, where local supersonic\n",
      "regions terminated by shock waves are present in the vicinity of the\n",
      "airfoil .  viscous effects are neglected, and a linearized theory of\n",
      "the perturbations due to harmonic oscillations of an aileron is\n",
      "developed .  a series solution for the pressure distribution is obtained,\n",
      "and numerical results for the nonsteady hinge moment, from the\n",
      "first approximation to the solution, are presented .  as a result of\n",
      "flutter analysis a stability boundary for transonic aileron buzz is\n",
      "obtained .  comparison of the theoretical results with experimental\n",
      "observations shows satisfactory agreement .\n",
      "\n",
      "================== Result 2 ==================\n",
      "two dimensional transonic unsteady flow with shock\n",
      "waves .\n",
      "  a study is made of the unsteady flow around an\n",
      "airfoil at transonic mach numbers, the situation being\n",
      "such that local supersonic regions terminated by\n",
      "shock-waves are present in the vicinity of the airfoil .  for\n",
      "the unsteady part of the flow, small perturbations\n",
      "technique is employed and the interaction with the shock\n",
      "wave is taken into account .  the case of an oscillating\n",
      "aileron is considered first, and a solution is derived\n",
      "for the pressure distribution on the aileron .  it is\n",
      "found that the solution has a simple form when the\n",
      "shock-wave is well ahead of the hinge axis of the\n",
      "aileron .  as the shock approaches the hinge-axis a\n",
      "correction must be added to the solution .  an\n",
      "interpretation of these results is given .  the results are\n",
      "compared with results of a theory which neglects the\n",
      "presence of the shock and it is found that both agree\n",
      "for m = 1 .  for m   1, however, neglecting the presence\n",
      "of the shock waves introduces errors of the order of\n",
      "magnitude (1 - m), where m is the local mach number\n",
      "behind the shock .\n",
      "  the theory is finally extended to include the case\n",
      "in which the whole airfoil oscillates, but only the\n",
      "solution for the subsonic region behind the shock is\n",
      "treated .  the role of the unsteady shock-boundary layer\n",
      "interaction is discussed and it is shown that this\n",
      "mechanism can be included in the results of the present\n",
      "theory .\n",
      "\n",
      "================== Result 3 ==================\n",
      "wing-tail interference as a cause of 'magnus' effects\n",
      "on a finned missile .\n",
      "  wing-tail interference is shown to cause large /magnus/ effects\n",
      "on a finned missile whose wings are deflected into an aileron\n",
      "setting .  a simple experimental method with water as the\n",
      "working medium is used to obtain low-speed magnus data on a rolling\n",
      "missile .  the missile is a slender cruciform configuration with\n",
      "all-movable wings and fixed tail fins .  magnus data are\n",
      "presented for angles of attack up to 15 and for the one (high) roll\n",
      "rate which accompanies a 30 aileron deflection angle of the\n",
      "wings .  tests conducted at zero roll rate but with the wing\n",
      "deflection maintained, revealed large forces in the magnus direction,\n",
      "thereby providing the basis for understanding magnus effects due\n",
      "to wing-tail interference .\n",
      "  a semiempirical theory is proposed to explain the experimental\n",
      "data .  a simplified model of the wake behind the wings is\n",
      "introduced to predict tail-interference factors .  good agreement with\n",
      "the data is obtained .\n",
      "  this magnus effect is opposite in direction to the classical\n",
      "magnus lift on a spinning cylinder ,. it is much larger than either\n",
      "that effect or the one on a missile with only one set of fins .\n",
      "wing-tail interference is the predominant source of the effect ,. roll rate\n",
      "only modifies the basic interference mechanism .\n",
      "\n",
      "================== Result 4 ==================\n",
      "on alternative forms for the basic equations of transonic\n",
      "flow theory .\n",
      "attention has been called by numerous authors to the\n",
      "possibility of certain alternative forms for the equations for\n",
      "transonic flow about thin wings .  it is the purpose of this note\n",
      "to contribute to this discussion and to indicate some reasons for\n",
      "the selection of one form of these in preference to another more\n",
      "widely used form .\n",
      "\n",
      "================== Result 5 ==================\n",
      "on the prediction of mixed subsonic/supersonic pressure\n",
      "distributions .\n",
      "  high-speed wind-tunnel results are analyzed to derive a\n",
      "semiempirical scheme for the prediction of transonic pressure\n",
      "distributions .  the supersonic and subsonic parts of the flow are\n",
      "treated separately, and then linked by an empirical shock\n",
      "pressure rise relation .  the significance of the empirical results is\n",
      "considered in relation to the physical mechanism of transonic\n",
      "flows .  it is also shown that theoretical solutions can be\n",
      "improved by introducing the empirical shock relation .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the results\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"================== Result {i + 1} ==================\")\n",
    "    print(docs[result[\"id\"]])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
