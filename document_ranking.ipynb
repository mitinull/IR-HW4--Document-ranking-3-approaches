{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing an Information Retrieval System with Document Ranking\n",
    "\n",
    "This project aims to augment the Information Retrieval (IR) system developed in the previous assignments by incorporating different Document Ranking strategies. You should use the Cranfield collection as the dataset. You can find\n",
    "that in the original format here or in the TREC XML format with binary tagging here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "In this project, you will implement three different approaches for document ranking, including the vector space model,\n",
    "the binary independence model, and the language model. Then, you need to compare these ranking models resorting\n",
    "to the evaluation criteria in Lecture 7. Key components and functionalities are as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⬜ Document Preprocessing\n",
    "\n",
    "Your project will begin by reading and preprocessing a collection of text documents\n",
    "– for each document you only need to retain the text with TITLE and TEXT tags. The dataset also contains\n",
    "queries and relevant documents to each query which will be useful in the evaluation phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  # For standard paths that work on both windows and linux\n",
    "import xml.etree.ElementTree as ET # For reading xml files\n",
    "from nltk.tokenize import RegexpTokenizer  # For tokenization\n",
    "from nltk.stem import PorterStemmer  # For stemming\n",
    "import numpy as np\n",
    "import math  # For calculating idf (math.log(N/df))\n",
    "from collections import Counter  # For calculating query's terms frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"cranfield-dataset\") / \"cran.all.1400.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== DOC 0 ========\n",
      "experimental investigation of the aerodynamics of a\n",
      "wing in a slipstream .\n",
      "  an experimental study of a wing in a propeller slipstream was\n",
      "made in order to determine the spanwise distribution of the l...\n",
      "======== DOC 1 ========\n",
      "simple shear flow past a flat plate in an incompressible fluid of small\n",
      "viscosity .\n",
      "in the study of high-speed viscous flow past a two-dimensional body it\n",
      "is usually necessary to consider a curved sho...\n"
     ]
    }
   ],
   "source": [
    "root = ET.parse(DATA_PATH).getroot()\n",
    "\n",
    "for i, doc in enumerate(root.findall('doc')):\n",
    "    print(f\"======== DOC {i} ========\")\n",
    "    print(doc.find('text').text[:200], \"...\", sep=\"\")\n",
    "    if i >= 1 : break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "docs_tokens = []\n",
    "collection_tokens = []\n",
    "posting_list = {}\n",
    "\n",
    "for doc_id, doc in enumerate(root.findall(\"doc\")):\n",
    "    text = doc.find(\"text\").text or \"\"\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [ps.stem(token) for token in tokens]\n",
    "\n",
    "    docs.append(text)\n",
    "    docs_tokens.append(tokens)\n",
    "\n",
    "    for token in tokens:\n",
    "        collection_tokens.append(token)\n",
    "\n",
    "    for term in tokens:\n",
    "        if posting_list.get(term) == None:\n",
    "            posting_list[term] = {}\n",
    "        \n",
    "        if posting_list[term].get(doc_id) == None:\n",
    "            posting_list[term][doc_id] = 0\n",
    "\n",
    "        posting_list[term][doc_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but(219 docs): [doc_id: frequency] {13: 2, 24: 1, 27: 1, 43: 1, 48: 2, 61: 1, 65: 1, 71: 2, 93: 1, 109: 2, 113: 1, 115: 1, 124: 1, 125: 1, 131: 1, 137: 1, 139: 1, 148: 1, 151: 1, 152: 1, 155: 2, 159: 1, 167: 1, 172: 1, 175: 1, 178: 1, 184: 1, 187: 1, 188: 1, 190: 1, 192: 1, 198: 2, 200: 1, 201: 4, 203: 1, 205: 1, 208: 1, 209: 1, 211: 2, 213: 1, 220: 1, 226: 1, 228: 1, 240: 1, 243: 1, 246: 1, 251: 2, 254: 2, 260: 1, 265: 1, 271: 1, 282: 1, 283: 1, 291: 1, 295: 1, 328: 4, 337: 2, 346: 1, 347: 1, 351: 1, 369: 1, 374: 1, 389: 1, 403: 2, 416: 1, 430: 1, 440: 1, 451: 1, 458: 2, 476: 2, 483: 1, 489: 1, 498: 2, 510: 1, 514: 1, 518: 1, 519: 1, 520: 1, 521: 1, 526: 1, 535: 1, 544: 1, 546: 1, 555: 1, 561: 1, 563: 1, 565: 1, 566: 1, 568: 1, 569: 1, 571: 1, 588: 1, 594: 1, 599: 1, 603: 1, 635: 1, 639: 1, 642: 1, 651: 1, 659: 1, 660: 1, 662: 1, 666: 1, 670: 1, 672: 1, 678: 1, 684: 2, 685: 1, 691: 1, 703: 2, 717: 1, 720: 1, 726: 1, 730: 1, 738: 1, 747: 1, 751: 1, 752: 2, 755: 1, 756: 2, 759: 1, 762: 1, 785: 1, 795: 1, 796: 3, 797: 2, 798: 1, 808: 1, 809: 1, 810: 1, 813: 1, 817: 1, 819: 1, 823: 1, 841: 1, 867: 1, 868: 1, 872: 1, 873: 1, 876: 1, 882: 1, 888: 1, 891: 1, 901: 1, 902: 1, 907: 1, 908: 1, 910: 1, 912: 1, 922: 1, 927: 1, 929: 1, 932: 1, 961: 3, 965: 2, 976: 1, 983: 1, 984: 1, 989: 1, 993: 1, 999: 2, 1000: 1, 1006: 1, 1011: 1, 1034: 1, 1039: 1, 1041: 1, 1046: 2, 1050: 1, 1053: 1, 1065: 1, 1067: 1, 1074: 1, 1077: 1, 1081: 2, 1083: 1, 1109: 1, 1130: 1, 1135: 1, 1164: 1, 1174: 1, 1177: 1, 1181: 1, 1184: 1, 1187: 2, 1188: 1, 1205: 1, 1206: 1, 1209: 1, 1217: 1, 1219: 1, 1224: 1, 1234: 1, 1237: 1, 1238: 2, 1241: 2, 1243: 2, 1244: 1, 1259: 1, 1264: 1, 1270: 1, 1276: 1, 1302: 1, 1308: 1, 1315: 1, 1319: 1, 1320: 1, 1321: 1, 1324: 1, 1336: 1, 1342: 1, 1369: 1, 1371: 1, 1372: 1, 1374: 2, 1379: 1, 1383: 1, 1384: 1, 1391: 1}\n"
     ]
    }
   ],
   "source": [
    "print(f\"but({len(posting_list['but'])} docs): [doc_id: frequency]\",posting_list[\"but\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'but's in doc_13 = 2\n"
     ]
    }
   ],
   "source": [
    "# test if above result is correct\n",
    "num_but_in_doc_13 = sum(np.array(docs[13].split()) == \"but\")\n",
    "print(\"Number of 'but's in doc_13 =\", num_but_in_doc_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(docs_scores, k):\n",
    "    result_docs_ids = docs_scores.argsort()[-k:][::-1]\n",
    "\n",
    "    results = [\n",
    "        {\"id\": result_docs_ids[i], \"score\": docs_scores[result_docs_ids[i]]}\n",
    "        for i in range(len(result_docs_ids))\n",
    "    ]\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"====================== Result {i + 1} ======================\")\n",
    "        print(result)\n",
    "        print(docs[result[\"id\"]][:100].replace(\"\\n\", \"\"), \"...\", sep=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⬜ Document Ranking – Space Vector Model\n",
    "\n",
    "You will implement a function for document ranking utilizing\n",
    "the tf-idf weighting approach. The function will take as input a query text and an integer indicating the number\n",
    "of top documents to be retrieved. To this end, you might need to store additional information about the ”term\n",
    "frequency” in each document and the ”document frequency” of each term. A good representation and sufficient\n",
    "data storage facilitate you in implementing other models too. You can choose between <u style=\"color:orangered\">different tf-idf variants</u>\n",
    "and need to discuss why your chosen approach is preferred.\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ◼ tf-idf variants\n",
    "\n",
    "I'm using ntc(regarding to slides) for both documents and queries.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "This is perfect because it considers the number of tokens occurring in a document or query.\n",
    "\n",
    "If someone repeats a word twice in a query it means the word is more important.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_score(query, k):\n",
    "    query = [ps.stem(token) for token in tokenizer.tokenize(query)]\n",
    "\n",
    "    query_term_frequency = Counter(query)\n",
    "\n",
    "    docs_scores = np.zeros(len(docs))\n",
    "\n",
    "    for term in posting_list:\n",
    "        idf = math.log(\n",
    "            len(docs) / len(posting_list[term]), 10\n",
    "        )  # Log base is 10 in the slides\n",
    "\n",
    "        term_query_weight = query_term_frequency[term] * idf\n",
    "\n",
    "        for doc_id in posting_list[term]:\n",
    "            tf = posting_list[term][doc_id]\n",
    "\n",
    "            term_doc_weight = tf * idf\n",
    "\n",
    "            docs_scores[doc_id] += term_query_weight * term_doc_weight\n",
    "\n",
    "    for i in range(len(docs_scores)):\n",
    "        docs_scores[i] /= len(docs_tokens[i]) or 1\n",
    "\n",
    "    print_results(docs_scores, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Result 1 ======================\n",
      "{'id': 63, 'score': 0.18509858343250643}\n",
      "unsteady oblique interaction of a shock wave with planedisturbances .  analysis is made of the flo...\n",
      "\n",
      "====================== Result 2 ======================\n",
      "{'id': 401, 'score': 0.09745768270811708}\n",
      "magnetohydrodynamics shocks .  a mathematical treatment of the coupled motion ofhydrodynamic flow ...\n",
      "\n",
      "====================== Result 3 ======================\n",
      "{'id': 64, 'score': 0.09550694068965461}\n",
      "convection of a pattern of vorticity through a shockwave .  an arbitrary weak spatial distribution...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cosine_score(\"papers on shock-sound wave interaction\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⬜ Document Ranking – Probabilistic Model\n",
    "\n",
    "You will implement a function for document ranking utilizing\n",
    "the Okapi BM25 basic weighting approach. The function will take as input a query text and an integer indicating\n",
    "the number of top documents to be retrieved. You do not need to fine-tune parameters b, k1, k3. Nevertheless,\n",
    "you have to <u>argue why the acquired parameters make sense</u>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⬜ Long queries – Probabilistic Model (Optional)\n",
    "\n",
    "Handle long queries by having your function <u>alternatively switch</u> between Okapi BM25 approaches based on the query length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ◼ argue why the acquired parameters make sense\n",
    "\n",
    "regarding to slides:\n",
    "The above tuning parameters should ideally be set to optimize performance\n",
    "on a development test collection. In the absence of such optimization,\n",
    "experiments have shown reasonable values are to \n",
    "<u style=\"color:orangered\">set k1 and k3 to a value between 1.2 and 2</u> and <u style=\"color:orangered\">b = 0.75</u>\n",
    "\n",
    "k1 = 1.5 makes sense because when tf becomes twice, the rsv changes less than twice.\n",
    "b = .75 makes sense because when a document is twice bigger it gets a score more than twice smaller.\n",
    "k3 = 1.5 makes sense. the same reason for k1 but this time for query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_doc_length = sum([len(doc) for doc in docs_tokens]) / len(docs_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsv_score(query, k):\n",
    "    query = [ps.stem(token) for token in tokenizer.tokenize(query)]\n",
    "\n",
    "    k1, k3, b = 1.5, 1.5, 0.75\n",
    "    threshold = 10\n",
    "\n",
    "    if len(query) < threshold:\n",
    "        k3 = 0  # If query is not long, don't consider k3.\n",
    "\n",
    "    docs_scores = np.zeros(len(docs))\n",
    "\n",
    "    query_term_frequency = Counter(query)\n",
    "\n",
    "    for doc_id in range(len(docs)):\n",
    "        for term in set(query):\n",
    "            if term in docs_tokens[doc_id]:\n",
    "                idf = math.log(len(docs) / len(posting_list[term]), 10)\n",
    "                tf_d = posting_list[term][doc_id]\n",
    "                tf_q = query_term_frequency[term]\n",
    "\n",
    "                factor1 = ((k1 + 1) * tf_d) / (\n",
    "                    k1 * ((1 - b) + b * len(docs_tokens[doc_id]) / avg_doc_length)\n",
    "                    + tf_d\n",
    "                )\n",
    "\n",
    "                factor2 = ((k3 + 1) * tf_q) / (k3 + tf_q)\n",
    "\n",
    "                docs_scores[doc_id] += idf * factor1 * factor2\n",
    "\n",
    "    print_results(docs_scores, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Result 1 ======================\n",
      "{'id': 63, 'score': 8.064827521193095}\n",
      "unsteady oblique interaction of a shock wave with planedisturbances .  analysis is made of the flo...\n",
      "\n",
      "====================== Result 2 ======================\n",
      "{'id': 131, 'score': 6.000580014244672}\n",
      "viscosity effects in sound waves of finite amplitude:in survey in mechanics .  this article has as...\n",
      "\n",
      "====================== Result 3 ======================\n",
      "{'id': 169, 'score': 5.8645299200697725}\n",
      "the interaction of a reflected shock wave with theboundary layer in a shock tube .  ideally, the r...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rsv_score(\"papers on shock-sound wave interaction\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⬜ Document Ranking – Language Model\n",
    "\n",
    "You will implement a function for document ranking utilizing\n",
    "the language model. The function will take as input a query text and an integer indicating the number of top\n",
    "documents to be retrieved. You can choose between Dirichlet smoothing or Jelinek-Mercer smoothing to avoid\n",
    "zeroes. You do not need to fine-tune parameters λ or α. Albeit, you need to discuss why your chosen methods\n",
    "and parameters are preferred.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ◼ discuss why your chosen methods and parameters are preferred\n",
    "\n",
    "Jelinek-Mercer because:\n",
    "  - It has good performance\n",
    "  - Easy to implement\n",
    "  - Fast (because we pre-compute collection model and document model)\n",
    "\n",
    "lambda = 0.5 because it is 0.5 in slides example and makes sense.\n",
    "when lambda = 0.5, we calculate score by paying attention to probability of occurring term in a document and probability of occurring term in a collection equally. in this way, less frequent terms become more important as much as they should. when a term has high collection frequency, the term increases scores of all documents, so it doesn't make a significant difference. but when a term is rare it just increases scores of the documents that it occurred in; hence this documents get a high score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiment': 470, 'investig': 524, 'of': 12671}\n"
     ]
    }
   ],
   "source": [
    "# Number of occurrences in the collection for each term.\n",
    "collection_frequency = Counter(collection_tokens)\n",
    "print({term: collection_frequency[term] for term in collection_tokens[:3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiment': 0.0020734531818683137, 'investig': 0.002311679717657439, 'of': 0.055899415462666815}\n"
     ]
    }
   ],
   "source": [
    "# Probability of occurrence in the collection for each term.\n",
    "collection_model = {\n",
    "    key: collection_frequency[key] / len(collection_tokens)\n",
    "    for key in collection_frequency\n",
    "}\n",
    "print({term:collection_model[term] for term in collection_tokens[:3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000562"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of all probabilities must be one. (Just for testing)\n",
    "sum([collection_model[term] for term in collection_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_0: {'experiment': 0.014388489208633094, 'investig': 0.007194244604316547, 'of': 0.07194244604316546, 'the': 0.08633093525179857, 'aerodynam': 0.007194244604316547, 'a': 0.050359712230215826, 'wing': 0.02158273381294964, 'in': 0.02877697841726619, 'slipstream': 0.03597122302158273, 'an': 0.02158273381294964, 'studi': 0.007194244604316547, 'propel': 0.007194244604316547, 'wa': 0.02877697841726619, 'made': 0.014388489208633094, 'order': 0.007194244604316547, 'to': 0.03597122302158273, 'determin': 0.007194244604316547, 'spanwis': 0.007194244604316547, 'distribut': 0.007194244604316547, 'lift': 0.02877697841726619, 'increas': 0.007194244604316547, 'due': 0.014388489208633094, 'at': 0.014388489208633094, 'differ': 0.02158273381294964, 'angl': 0.007194244604316547, 'attack': 0.007194244604316547, 'and': 0.007194244604316547, 'free': 0.007194244604316547, 'stream': 0.007194244604316547, 'veloc': 0.007194244604316547, 'ratio': 0.007194244604316547, 'result': 0.007194244604316547, 'were': 0.007194244604316547, 'intend': 0.007194244604316547, 'part': 0.014388489208633094, 'as': 0.007194244604316547, 'evalu': 0.014388489208633094, 'basi': 0.007194244604316547, 'for': 0.014388489208633094, 'theoret': 0.007194244604316547, 'treatment': 0.007194244604316547, 'thi': 0.014388489208633094, 'problem': 0.007194244604316547, 'compar': 0.007194244604316547, 'span': 0.007194244604316547, 'load': 0.007194244604316547, 'curv': 0.007194244604316547, 'togeth': 0.007194244604316547, 'with': 0.014388489208633094, 'support': 0.007194244604316547, 'evid': 0.007194244604316547, 'show': 0.007194244604316547, 'that': 0.007194244604316547, 'substanti': 0.007194244604316547, 'increment': 0.014388489208633094, 'produc': 0.007194244604316547, 'by': 0.007194244604316547, 'destal': 0.02158273381294964, 'or': 0.007194244604316547, 'boundari': 0.007194244604316547, 'layer': 0.007194244604316547, 'control': 0.007194244604316547, 'effect': 0.014388489208633094, 'integr': 0.007194244604316547, 'remain': 0.007194244604316547, 'after': 0.007194244604316547, 'subtract': 0.007194244604316547, 'found': 0.007194244604316547, 'agre': 0.007194244604316547, 'well': 0.007194244604316547, 'potenti': 0.007194244604316547, 'flow': 0.007194244604316547, 'theori': 0.007194244604316547, 'empir': 0.007194244604316547, 'specif': 0.007194244604316547, 'configur': 0.007194244604316547, 'experi': 0.007194244604316547}\n",
      "doc_1: {'simpl': 0.01015228426395939, 'shear': 0.01015228426395939, 'flow': 0.030456852791878174, 'past': 0.02030456852791878, 'a': 0.04568527918781726, 'flat': 0.015228426395939087, 'plate': 0.015228426395939087, 'in': 0.03553299492385787, 'an': 0.01015228426395939, 'incompress': 0.01015228426395939, 'fluid': 0.01015228426395939, 'of': 0.030456852791878174, 'small': 0.01015228426395939, 'viscos': 0.01015228426395939, 'the': 0.09137055837563451, 'studi': 0.01015228426395939, 'high': 0.005076142131979695, 'speed': 0.005076142131979695, 'viscou': 0.01015228426395939, 'two': 0.01015228426395939, 'dimension': 0.01015228426395939, 'bodi': 0.01015228426395939, 'it': 0.01015228426395939, 'is': 0.025380710659898477, 'usual': 0.005076142131979695, 'necessari': 0.005076142131979695, 'to': 0.01015228426395939, 'consid': 0.01015228426395939, 'curv': 0.005076142131979695, 'shock': 0.01015228426395939, 'wave': 0.01015228426395939, 'emit': 0.005076142131979695, 'from': 0.01015228426395939, 'nose': 0.005076142131979695, 'or': 0.005076142131979695, 'lead': 0.005076142131979695, 'edg': 0.005076142131979695, 'consequ': 0.005076142131979695, 'there': 0.005076142131979695, 'exist': 0.005076142131979695, 'inviscid': 0.015228426395939087, 'rotat': 0.01015228426395939, 'region': 0.005076142131979695, 'between': 0.005076142131979695, 'and': 0.01015228426395939, 'boundari': 0.025380710659898477, 'layer': 0.025380710659898477, 'such': 0.005076142131979695, 'situat': 0.01015228426395939, 'aris': 0.005076142131979695, 'for': 0.005076142131979695, 'instanc': 0.005076142131979695, 'hyperson': 0.01015228426395939, 'somewhat': 0.005076142131979695, 'differ': 0.005076142131979695, 'prandtl': 0.01015228426395939, 's': 0.01015228426395939, 'classic': 0.005076142131979695, 'problem': 0.02030456852791878, 'origin': 0.005076142131979695, 'free': 0.015228426395939087, 'stream': 0.015228426395939087, 'outsid': 0.005076142131979695, 'irrot': 0.005076142131979695, 'while': 0.005076142131979695, 'must': 0.005076142131979695, 'be': 0.02030456852791878, 'as': 0.005076142131979695, 'possibl': 0.005076142131979695, 'effect': 0.005076142131979695, 'vortic': 0.01015228426395939, 'have': 0.005076142131979695, 'been': 0.005076142131979695, 'recent': 0.005076142131979695, 'discuss': 0.01015228426395939, 'by': 0.01015228426395939, 'ferri': 0.005076142131979695, 'libbi': 0.005076142131979695, 'present': 0.005076142131979695, 'paper': 0.005076142131979695, 'investig': 0.005076142131979695, 'can': 0.01015228426395939, 'shown': 0.005076142131979695, 'that': 0.01015228426395939, 'thi': 0.005076142131979695, 'again': 0.005076142131979695, 'treat': 0.005076142131979695, 'approxim': 0.005076142131979695, 'onli': 0.005076142131979695, 'novel': 0.005076142131979695, 'featur': 0.005076142131979695, 'ha': 0.005076142131979695, 'constant': 0.005076142131979695, 'here': 0.005076142131979695, 'restrict': 0.005076142131979695, 'steadi': 0.005076142131979695}\n",
      "doc_2: {'the': 0.08, 'boundari': 0.08, 'layer': 0.08, 'in': 0.04, 'simpl': 0.04, 'shear': 0.04, 'flow': 0.08, 'past': 0.04, 'a': 0.04, 'flat': 0.04, 'plate': 0.04, 'equat': 0.04, 'are': 0.04, 'present': 0.04, 'for': 0.04, 'steadi': 0.04, 'incompress': 0.04, 'with': 0.04, 'no': 0.04, 'pressur': 0.04, 'gradient': 0.04}\n"
     ]
    }
   ],
   "source": [
    "# Probability of occurrence in the documents.\n",
    "docs_models = [\n",
    "    {term: tf / len(doc_tokens) for term, tf in Counter(doc_tokens).items()}\n",
    "    for doc_tokens in docs_tokens\n",
    "]\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"doc_{i}:\", docs_models[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_0: 0.9999999999999981\n",
      "doc_1: 1.0000000000000009\n",
      "doc_2: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# Sum of all probabilities must be one. (Just for testing)\n",
    "for i in range(3):\n",
    "    print(f\"doc_{i}:\", sum([docs_models[i][term] for term in docs_models[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_model_score(query, k):\n",
    "    query = [ps.stem(token) for token in tokenizer.tokenize(query)]\n",
    "\n",
    "    l = 0.5\n",
    "\n",
    "    docs_scores = np.ones(len(docs))\n",
    "\n",
    "    for doc_id in range(len(docs)):\n",
    "        for term in query:\n",
    "            docs_scores[doc_id] *= (\n",
    "                l * (docs_models[doc_id].get(term) or 0) + (1 - l) * collection_model[term]\n",
    "            )\n",
    "\n",
    "    print_results(docs_scores, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Result 1 ======================\n",
      "{'id': 63, 'score': 4.542787301559045e-13}\n",
      "unsteady oblique interaction of a shock wave with planedisturbances .  analysis is made of the flo...\n",
      "\n",
      "====================== Result 2 ======================\n",
      "{'id': 169, 'score': 6.384999445745297e-15}\n",
      "the interaction of a reflected shock wave with theboundary layer in a shock tube .  ideally, the r...\n",
      "\n",
      "====================== Result 3 ======================\n",
      "{'id': 131, 'score': 5.940336349852554e-15}\n",
      "viscosity effects in sound waves of finite amplitude:in survey in mechanics .  this article has as...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "language_model_score(\"papers on shock-sound wave interaction\", 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
